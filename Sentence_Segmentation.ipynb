{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentence Segmentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3Hr/Uu/MwLRqo7PPPhRKL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabhpurohit/NLP-Basics-Project/blob/master/Sentence_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYQFwdPn5r7_",
        "colab_type": "text"
      },
      "source": [
        "Sentence segmentation is the process of determining the longest processing units, within a text, consisting of one or more words. This task involves identifying sentence boundaries between words. Sentence segmentation is frequently referred to as sentence boundary detection or sentence boundary disambiguation. Basically it determines, how a text should be divided into sentences for further processing.\n",
        "\n",
        "\n",
        "\n",
        "Most written languages have punctuation marks which occur at sentence boundaries. It may look an easy task since we can easily read a string and identify the punctuation marks in the strings and partition the text into sentences. This may be easy for the punctuation marks such as ‘!’ or ‘?’ But for a period ‘.’ this splitting may not be correct. Because a period ‘.’ is ambiguous. For example, ‘Dr.’ or ‘Mr.’ or ‘2.57’ where period does not act as sentence boundary. Just like POS tagging or tokenization, again context play a crucial role here.\n",
        "\n",
        "\n",
        "\n",
        "Instead of deterministic rule-based method for sentence detection, a probabilistic method works better. We train a system using large text documents where words or more accurately tokens are annotated according to POS tag list. Along with that we also annotate sentence boundaries. Ideally training for POS tagging, tokenization and sentence detection happen at the same time. \n",
        "\n",
        "\n",
        "\n",
        "Riley in 1989 published first paper describing a trainable sentence segmentation algorithm. The algorithm was based on classification and regression tree. The method classified periods according to contextual features, describing the single word preceding and following the period. These contextual features included word length, punctuation after the period, abbreviation class, case of the word, and the probability of the word occurring at beginning or end of a sentence. The method was used to train using 25 millions words and achieved 99.8% accuracy when tested on another documents or corpus. \n",
        "\n",
        "\n",
        "\n",
        "In our present time, recurrent neural networks or RNN, a deep learning method, is used to build machine learning based models for sentence segmentation. We will now see, how sentence segmentation happens in python.\n",
        "\n",
        "\n",
        "\n",
        "A document or data can be split into sentences using the method sent_tokenize(). For that we need to start at the following. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXrIAv6w4-sR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4fb9ba98-da92-4fff-b495-5a02719ea2cf"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laqmt5lZ5EJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = \"Hello Mr. Rahul, welcome to Spotle masterclass. Today we are talking about sentence segmentation.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jzj2o085L1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8f1c314c-ed0d-4b75-8a98-4ac4cddf5471"
      },
      "source": [
        "sent_tokenize(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello Mr. Rahul, welcome to Spotle masterclass.',\n",
              " 'Today we are talking about sentence segmentation.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUzSYyyI5N8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}